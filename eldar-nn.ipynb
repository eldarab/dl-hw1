{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 784  # size of MNIST picture flattened (28x28)\n",
    "hid_dim = 32  # heuristic I found online\n",
    "out_dim = 10  # num classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "# MNIST Dataset (Images and Labels)\n",
    "\n",
    "batch_size = 100\n",
    "data_transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1, 28*28))])\n",
    "# target_transform = transforms.Lambda(lambda x: F.one_hot(torch.tensor(x), 10))  # num classes\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=data_transform,\n",
    "#                             target_transform=target_transform,\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=data_transform)\n",
    "#                            target_transform=target_transform)\n",
    "\n",
    "# Dataset Loader (Input Pipline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(s):\n",
    "    return 1 / (1 + torch.exp(-s))\n",
    "\n",
    "def sigmoid_prime(s):\n",
    "    # derivative of sigmoid\n",
    "    # s: sigmoid x\n",
    "    return s * (1 - s)\n",
    "\n",
    "def tanh(t):\n",
    "    return torch.div(torch.exp(t) - torch.exp(-t), torch.exp(t) + torch.exp(-t))\n",
    "\n",
    "def tanh_prime(t):\n",
    "    # derivative of tanh\n",
    "    # t: tanh x\n",
    "    return 1 - t*t\n",
    "\n",
    "def softmax(x):\n",
    "    # x (batch, num_classes)\n",
    "    # only operates on last dimension\n",
    "    return x.exp() / x.exp().sum(-1, keepdim=True)\n",
    "\n",
    "def ce_loss(x, y):  \n",
    "    # x (batch, num_classes) - network outputs\n",
    "    # y (batch, 1) - true classes (indexes, NOT one-hot)\n",
    "    \n",
    "    loss = 0\n",
    "    assert x.shape[0] == y.shape[0] # make sure batch sizes are the same\n",
    "    nll = - torch.log(softmax(x))\n",
    "    for prob, true_class in zip(nll, y):\n",
    "        loss += prob[true_class]\n",
    "    return loss / x.shape[0]\n",
    "\n",
    "def ce_loss_prime(x, y):\n",
    "    # x (batch, num_classes) - network outputs\n",
    "    # y (batch, 1) - true classes (indexes, NOT one-hot)\n",
    "    \n",
    "    return softmax(x) - F.one_hot(y, x.size(1)).squeeze()\n",
    "\n",
    "def eval_model(model, dataloader):\n",
    "    if isinstance(model, torch.nn.Module):\n",
    "        model.eval()\n",
    "    loss, accuracy = 0, 0\n",
    "    for batch_idx, (x, y) in enumerate(dataloader):\n",
    "        out = model(x.view(-1,28*28))\n",
    "        accuracy += accuracy_score(y, out.argmax(1))\n",
    "        loss += F.cross_entropy(out, y)\n",
    "    return loss.item() / len(dataloader), accuracy / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, in_dim=784, hid_dim=32, out_dim=10, activation=\"tanh\"):\n",
    "        # architecture\n",
    "        self.in_dim = in_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.device = 'cpu' # 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        # parameters\n",
    "        self.W1 = torch.randn(self.in_dim, self.hid_dim, device=self.device, requires_grad=False)\n",
    "        self.b1 = torch.ones(self.hid_dim, device=self.device, requires_grad=False)\n",
    "        self.W2 = torch.randn(self.hid_dim, self.out_dim, device=self.device, requires_grad=False)\n",
    "        self.b2 = torch.ones(self.out_dim, device=self.device, requires_grad=False)\n",
    "        \n",
    "        # activations\n",
    "        if activation == \"tanh\":\n",
    "            self.activation = tanh\n",
    "            self.activation_prime = tanh_prime\n",
    "        if activation == \"sigmoid\":\n",
    "            self.activation = sigmoid\n",
    "            self.activation_prime = sigmoid_prime\n",
    "        if activation == \"relu\":\n",
    "            self.activation = relu\n",
    "            self.activation_prime = relu_prime\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = X.to(self.device)\n",
    "                                                          # (batch, in_dim)\n",
    "        Z1 = torch.matmul(X, self.W1) + self.b1           # (batch, hid_dim)\n",
    "        self.h = self.activation(Z1)                      # (batch, hid_dim)\n",
    "        Z2 = torch.matmul(self.h, self.W2) + self.b2      # (batch, out_dim)\n",
    "        return self.activation(Z2)                        # (batch, out_dim)\n",
    "        \n",
    "    def backward(self, X, y, out, lr=1e-3):\n",
    "        X = X.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        out = out.to(self.device)\n",
    "        batch_size = X.size(0)\n",
    "        \n",
    "        dl_dout = (1 / batch_size) * ce_loss_prime(out, y)  # (batch, out_dim)\n",
    "        dl_dZ2 = dl_dout * self.activation_prime(dl_dout)   # (batch, out_dim)\n",
    "        dl_dW2 = torch.matmul(self.h.t(), dl_dZ2)           # (hid_dim, out_dim)\n",
    "        dl_db2 = torch.matmul(torch.ones(batch_size), dl_dZ2)        # (out_dim)\n",
    "        dl_dH = torch.matmul(dl_dZ2, self.W2.t())           # (batch, hid_dim)\n",
    "        dl_dZ1 = dl_dH * self.activation_prime(dl_dH)       # (batch, hid_dim)\n",
    "        dl_dW1 = torch.matmul(X.t(), dl_dZ1)                # (in_dim, hid_dim)\n",
    "        dl_db1 = torch.matmul(torch.ones(batch_size), dl_dZ1)       # (hid_dim)\n",
    "        \n",
    "        self.W1 -= lr * dl_dW1\n",
    "        self.b1 -= lr * dl_db1\n",
    "        self.W2 -= lr * dl_dW2\n",
    "        self.b2 -= lr * dl_db2\n",
    "        \n",
    "    def __call__(self, X):\n",
    "        return self.forward(X)\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        # forward + backward pass for training\n",
    "        o = self.forward(X)\n",
    "        self.backward(X, y, o)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_model = nn.Sequential(\n",
    "    nn.Linear(in_features=in_dim, out_features=hid_dim),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(in_features=hid_dim, out_features=out_dim),\n",
    "    nn.Tanh()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    in_dim=784,\n",
    "    hid_dim=32,\n",
    "    out_dim=10,\n",
    "    activation=\"tanh\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating models before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt_model train \t\t loss 2.29968505859375 \t accuracy 0.10488333333333336\n",
      "pt_model test \t\t loss 2.297424774169922 \t accuracy 0.1035\n",
      "he_model train \t\t loss 2.6837459309895833 \t accuracy 0.07696666666666666\n",
      "he_model test \t\t loss 2.678391418457031 \t accuracy 0.08120000000000005\n"
     ]
    }
   ],
   "source": [
    "print(\"pt_model train \\t\\t loss {} \\t accuracy {}\".format(*eval_model(pt_model, train_loader)))\n",
    "print(\"pt_model test \\t\\t loss {} \\t accuracy {}\".format(*eval_model(pt_model, test_loader)))\n",
    "print(\"he_model train \\t\\t loss {} \\t accuracy {}\".format(*eval_model(model, train_loader)))\n",
    "print(\"he_model test \\t\\t loss {} \\t accuracy {}\".format(*eval_model(model, test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our model (HADATZ ELDATZ --YOTAMTZ--)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx: 0\tloss: 2.8014132976531982\n",
      "batch_idx: 1\tloss: 2.252896547317505\n",
      "batch_idx: 2\tloss: 2.021705389022827\n",
      "batch_idx: 3\tloss: 1.9031797647476196\n",
      "batch_idx: 4\tloss: 1.8867870569229126\n",
      "batch_idx: 5\tloss: 1.8272193670272827\n",
      ">>>>> epoch: 0\t train accuracy: 0.38018333333333304\n",
      ">>>>> epoch: 0\t test accuracy: 0.47130000000000005\n",
      "batch_idx: 0\tloss: 1.7823683023452759\n",
      "batch_idx: 1\tloss: 1.8810172080993652\n",
      "batch_idx: 2\tloss: nan\n",
      "batch_idx: 3\tloss: nan\n",
      "batch_idx: 4\tloss: nan\n",
      "batch_idx: 5\tloss: nan\n",
      ">>>>> epoch: 1\t train accuracy: 0.19643333333333288\n",
      ">>>>> epoch: 1\t test accuracy: 0.09799999999999995\n",
      "batch_idx: 0\tloss: nan\n",
      "batch_idx: 1\tloss: nan\n",
      "batch_idx: 2\tloss: nan\n",
      "batch_idx: 3\tloss: nan\n",
      "batch_idx: 4\tloss: nan\n",
      "batch_idx: 5\tloss: nan\n",
      ">>>>> epoch: 2\t train accuracy: 0.09871666666666662\n",
      ">>>>> epoch: 2\t test accuracy: 0.09799999999999995\n",
      "batch_idx: 0\tloss: nan\n",
      "batch_idx: 1\tloss: nan\n",
      "batch_idx: 2\tloss: nan\n",
      "batch_idx: 3\tloss: nan\n",
      "batch_idx: 4\tloss: nan\n",
      "batch_idx: 5\tloss: nan\n",
      ">>>>> epoch: 3\t train accuracy: 0.09871666666666679\n",
      ">>>>> epoch: 3\t test accuracy: 0.09799999999999995\n",
      "batch_idx: 0\tloss: nan\n",
      "batch_idx: 1\tloss: nan\n",
      "batch_idx: 2\tloss: nan\n",
      "batch_idx: 3\tloss: nan\n",
      "batch_idx: 4\tloss: nan\n",
      "batch_idx: 5\tloss: nan\n",
      ">>>>> epoch: 4\t train accuracy: 0.09871666666666686\n",
      ">>>>> epoch: 4\t test accuracy: 0.09799999999999995\n",
      "batch_idx: 0\tloss: nan\n",
      "batch_idx: 1\tloss: nan\n",
      "batch_idx: 2\tloss: nan\n",
      "batch_idx: 3\tloss: nan\n",
      "batch_idx: 4\tloss: nan\n",
      "batch_idx: 5\tloss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-db1a9957715f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mepoch_test_accuracy\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \"\"\"\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[1;31m# put it from HWC to CHW format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_accuracy_list = []\n",
    "test_accuracy_list = []\n",
    "\n",
    "lr = 1e-2\n",
    "epochs = 10 \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_train_accuracy = 0\n",
    "    epoch_test_accuracy = 0\n",
    "    \n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        out = model(x.view(-1,28*28))\n",
    "        loss = F.cross_entropy(out, y)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            epoch_train_accuracy += accuracy_score(y, out.argmax(1))\n",
    "        model.backward(x.view(-1,28*28), y, out, lr)\n",
    "        if batch_idx%100==0:\n",
    "            print(f'batch_idx: {int(batch_idx/100)}\\tloss: {loss}')\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x, y) in enumerate(test_loader):\n",
    "            out = model(x.view(-1,28*28))\n",
    "            epoch_test_accuracy += accuracy_score(y, out.argmax(1))\n",
    "    train_accuracy = epoch_train_accuracy / len(train_loader)\n",
    "    test_accuracy = epoch_test_accuracy / len(test_loader)\n",
    "    print(f\">>>>> epoch: {epoch}\\t train accuracy: {train_accuracy}\")\n",
    "    print(f\">>>>> epoch: {epoch}\\t test accuracy: {test_accuracy}\")\n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "    test_accuracy_list.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Their model (MARK ZUCKERBERG'S MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_accuracy_list = []\n",
    "test_accuracy_list = []\n",
    "\n",
    "lr = 1e-2\n",
    "epochs = 10\n",
    "\n",
    "pt_model.train()\n",
    "optimizer = torch.optim.SGD(pt_model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_train_accuracy = 0\n",
    "    epoch_test_accuracy = 0\n",
    "    \n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        out = pt_model(x.view(-1,28*28))\n",
    "        with torch.no_grad():\n",
    "            epoch_train_accuracy += accuracy_score(y, out.argmax(1))\n",
    "        loss = torch.nn.functional.cross_entropy(out, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx%100==0:\n",
    "            print(f'batch_idx: {int(batch_idx/100)}\\tloss: {loss}')\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x, y) in enumerate(test_loader):\n",
    "            out = pt_model(x.view(-1,28*28))\n",
    "            epoch_test_accuracy += accuracy_score(y, out.argmax(1))\n",
    "    train_accuracy = epoch_train_accuracy / len(train_loader)\n",
    "    test_accuracy = epoch_test_accuracy / len(test_loader)\n",
    "    print(f\">>>>> epoch: {epoch}\\t train accuracy: {train_accuracy}\")\n",
    "    print(f\">>>>> epoch: {epoch}\\t test accuracy: {test_accuracy}\")\n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "    test_accuracy_list.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "Test and train accuracy curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fig, loss_ax = plt.subplots()\n",
    "\n",
    "plt.plot(train_accuracy_list, label='Train Accuracy')\n",
    "plt.plot(test_accuracy_list, label='Test Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating models after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pt_model train \\t\\t loss {} \\t accuracy {}\".format(*eval_model(pt_model, train_loader)))\n",
    "print(\"pt_model test \\t\\t loss {} \\t accuracy {}\".format(*eval_model(pt_model, test_loader)))\n",
    "print(\"he_model train \\t\\t loss {} \\t accuracy {}\".format(*eval_model(model, train_loader)))\n",
    "print(\"he_model test \\t\\t loss {} \\t accuracy {}\".format(*eval_model(model, test_loader)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
